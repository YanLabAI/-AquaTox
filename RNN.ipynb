{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bf618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14b65832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-09T13:48:50.997794Z",
     "start_time": "2021-11-09T13:48:50.950091Z"
    },
    "code_folding": [
     2,
     8,
     51,
     56,
     113
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# k_flod\n",
    "def data_train_kf(data, hidden_size=200, n_layers=2, n_epoch=100, batch_size=16, USE_GPU = False, set_cv=5):\n",
    "    def createTensor(tensor):\n",
    "        if USE_GPU:\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            tensor = tensor.to(device)\n",
    "        return tensor\n",
    "\n",
    "    class RNNClassifier(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, num_layers = 1, bidirectional = True):\n",
    "            super(RNNClassifier, self).__init__()\n",
    "            self.hidden_size = hidden_size\n",
    "            self.num_layers = num_layers\n",
    "            self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "            self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "            self.gru = torch.nn.GRU(hidden_size, hidden_size, num_layers, bidirectional = bidirectional)\n",
    "\n",
    "            self.fc = torch.nn.Linear(hidden_size * self.num_directions, output_size)\n",
    "\n",
    "        def initHidden(self, batch_size):\n",
    "            hidden = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size)\n",
    "            return createTensor(hidden)\n",
    "\n",
    "        def forward(self, input, seq_lengths):\n",
    "            input = input.t()\n",
    "            batch_size = input.size(1)\n",
    "            hidden = self.initHidden(batch_size)\n",
    "\n",
    "\n",
    "            embedding = self.embedding(input)\n",
    "            gru_input = pack_padded_sequence(embedding, seq_lengths)\n",
    "            output, hidden = self.gru(gru_input, hidden)\n",
    "            if self.num_directions == 2:\n",
    "                hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim = 1)\n",
    "            else:\n",
    "                hidden_cat = hidden[-1]\n",
    "\n",
    "            fc_output = self.fc(hidden_cat)\n",
    "            return fc_output\n",
    "\n",
    "    # smiles to ASCIIlist\n",
    "    def smiles_to_ASCIIlist(smiles_list):\n",
    "        ASCIIlist = [ord(smiles) for smiles in smiles_list]\n",
    "        return ASCIIlist\n",
    "\n",
    "\n",
    "    def makeTensors(smiles_list, tox_list):\n",
    "        smiles_sequences = [smiles_to_ASCIIlist(smiles) for smiles in smiles_list]\n",
    "        smiles_seq_lens = torch.LongTensor([len(name_ASCII) for name_ASCII in smiles_sequences])\n",
    "\n",
    "        smiles_tensor = torch.zeros(len(smiles_sequences), smiles_seq_lens.max()).long()\n",
    "        for index, (smiles_sequence, smiles_seq_len) in enumerate(zip(smiles_sequences, smiles_seq_lens), 0):\n",
    "            smiles_tensor[index, 0:smiles_seq_len] = torch.LongTensor(smiles_sequence)\n",
    "\n",
    "        ordered_smiles_seq_lens, len_indexes = smiles_seq_lens.sort(dim = 0, descending = True)\n",
    "        ordered_smiles_tensor = smiles_tensor[len_indexes]\n",
    "        ordered_tox_list = tox_list[len_indexes]\n",
    "\n",
    "        return createTensor(ordered_smiles_tensor), createTensor(ordered_smiles_seq_lens), createTensor(ordered_tox_list) \n",
    "\n",
    "    def train():\n",
    "        loss = 0.0\n",
    "        for batch_index, (smiles, tox) in enumerate(train_loader):\n",
    "\n",
    "            inputs, seq_lens, targets = makeTensors(smiles, tox) \n",
    "            outputs = classifier_model(inputs, seq_lens)\n",
    "            targets = targets.to(torch.float32).reshape(-1,1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss += loss.item()\n",
    "\n",
    "            if batch_index % 10 == 9:\n",
    "                print('time_elapsed: {:.1f}m {:.1f}s, Epoch {}, '.format(timePassed(start_time)[0], timePassed(start_time)[1], epoch), end = '')\n",
    "                print(f'[{(batch_index+1) * len(inputs)} / {len(training_set)}] ', end = '')\n",
    "                print(f'loss = {loss / ((batch_index+1) * len(inputs))}')\n",
    "\n",
    "        return loss/len(train_loader)\n",
    "\n",
    "    def test():\n",
    "        correct = 0\n",
    "        total_samples = len(test_set)\n",
    "        with torch.no_grad():\n",
    "            pred = []\n",
    "            obs = []\n",
    "            for i, (smiles, tox) in enumerate(test_loader):\n",
    "                inputs, seq_lens, targets = makeTensors(smiles, tox)\n",
    "                outputs = classifier_model(inputs, seq_lens)\n",
    "                pred.append(outputs.data)\n",
    "                obs.append(targets.data.reshape(-1,1))\n",
    "            pred = np.vstack(pred).ravel()\n",
    "            obs = np.vstack(obs).ravel()\n",
    "            r2 = r2_score(obs, pred)\n",
    "            Mse = mse(obs, pred)\n",
    "            print('r2 on test: %.3f %%' % (100 * r2), 'mse on test: %.5f \\n' % (Mse))\n",
    "        return r2, Mse, pred, obs\n",
    "\n",
    "    def timePassed(start_time):\n",
    "        time_passed = time.time() - start_time\n",
    "        minute = math.floor(time_passed / 60)\n",
    "        second = time_passed - minute * 60\n",
    "        return [minute, second]\n",
    "\n",
    "    seed = 1\n",
    "    os.makedirs(\"./results/{}/DL/{}/RNN/test/\".format(data, seed), exist_ok=True)\n",
    "    os.makedirs(\"./results/{}/DL/{}/RNN/train/\".format(data, seed), exist_ok=True)\n",
    "    \n",
    "    # data load\n",
    "    train_mols = Chem.SDMolSupplier(\"./data/{}/{}_training.sdf\".format(data, data))\n",
    "    train_smiles = [Chem.MolToSmiles(mol) for mol in train_mols]\n",
    "    train_smiles_len = [len(smiles) for smiles in train_smiles]\n",
    "    train_tox = [float(mol.GetProp(\"Tox\")) for mol in train_mols]\n",
    "    training_set = [(train_smiles[i], train_tox[i]) for i in range(len(train_smiles))]\n",
    "\n",
    "    test_mols = Chem.SDMolSupplier(\"./data/{}/{}_prediction.sdf\".format(data, data))\n",
    "    test_smiles = [Chem.MolToSmiles(mol) for mol in test_mols]\n",
    "    test_smiles_len = [len(smiles) for smiles in test_smiles]\n",
    "    test_tox = [float(mol.GetProp(\"Tox\")) for mol in test_mols]\n",
    "    test_set = [(test_smiles[i], test_tox[i]) for i in range(len(test_smiles))]\n",
    "\n",
    "    base_indices = np.arange(0,len(train_tox))\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(base_indices)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(base_indices)\n",
    "    \n",
    "    step = int(len(train_tox)/set_cv)\n",
    "    pred_kflod = pd.DataFrame(index=range(len(train_tox)), columns=[\"cv1~{}\".format(set_cv), \"True\"])\n",
    "\n",
    "    for cv in range(set_cv):\n",
    "        print(\"*\"*20, \"Kflod\", cv ,\"*\"*20)\n",
    "        index = base_indices\n",
    "        if cv < set_cv-1:\n",
    "            index_train = np.concatenate([index[:cv*step],index[(cv+1)*step:]], axis=0)\n",
    "            index_val = index[cv*step:(cv+1)*step]\n",
    "        else: \n",
    "            index_train = index[0:cv*step]\n",
    "            index_val = index[cv*step:]\n",
    "\n",
    "        n_chars = 0\n",
    "        for smiles in train_smiles:\n",
    "            for char in smiles:\n",
    "                if n_chars < ord(char):\n",
    "                    n_chars = ord(char)\n",
    "        for smiles in test_smiles:\n",
    "            for char in smiles:\n",
    "                if n_chars < ord(char):\n",
    "                    n_chars = ord(char)\n",
    "        n_chars = n_chars+1\n",
    "        output_size = 1\n",
    "        batch_size = 16\n",
    "        train_loader = DataLoader(dataset = [training_set[index] for index in index_train], batch_size = batch_size, shuffle = True)\n",
    "        test_loader = DataLoader(dataset = [training_set[index] for index in index_val], batch_size = batch_size, shuffle = False)\n",
    "\n",
    "        classifier_model = RNNClassifier(n_chars, hidden_size, output_size, n_layers) # input_size, hidden_size, output_size, num_layers\n",
    "        if USE_GPU:\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            classifier_model.to(device)\n",
    "\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(classifier_model.parameters(), lr = 0.001, weight_decay=10 ** (-5.0))\n",
    "\n",
    "        # training and test\n",
    "        start_time = time.time()\n",
    "        print(\"The num of total training epochs is %d. \" % n_epoch)\n",
    "        r2_list = []\n",
    "        Mse_list = []\n",
    "        best_r2 = 0\n",
    "        for epoch in range(n_epoch):\n",
    "            train()\n",
    "            r2, Mse, pred, obs = test()\n",
    "            r2_list.append(r2)\n",
    "            Mse_list.append(Mse)\n",
    "            if best_r2 < r2:\n",
    "                best_r2 = r2\n",
    "                pred_kflod.iloc[index_val,0] = pred.reshape(1,-1)\n",
    "                pred_kflod.iloc[index_val,1] = obs.reshape(1,-1)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(1, n_epoch+1), r2_list)\n",
    "        plt.plot(np.arange(1, n_epoch+1), Mse_list)\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"r2 & MSE\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "    display(pred_kflod)\n",
    "    pred_kflod.to_csv(\"./results/{}/DL/{}/RNN/train//kf_pred_all.csv\".format(data, seed), index=0)\n",
    "    print(r2_score(pred_kflod.iloc[:,1], pred_kflod.iloc[:,0]))\n",
    "\n",
    "data_train_kf(\"IGC50\", hidden_size=200, n_layers=2, n_epoch=100, batch_size=16, USE_GPU = False, set_cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43585f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "def data_train_test(data, hidden_size=200, n_layers=2, n_epoch=100, batch_size=16, USE_GPU = False):\n",
    "    \"\"\"\n",
    "    data: tox data name\n",
    "    \"\"\"\n",
    "    \n",
    "    def createTensor(tensor):\n",
    "        if USE_GPU:\n",
    "            device = torch.device(\"cuda:0\")\n",
    "            tensor = tensor.to(device)\n",
    "        return tensor\n",
    "\n",
    "    class RNNRegress(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, num_layers = 1, bidirectional = True):\n",
    "            super(RNNRegress, self).__init__()\n",
    "            self.hidden_size = hidden_size\n",
    "            self.num_layers = num_layers\n",
    "            self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "            self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "            self.gru = torch.nn.GRU(hidden_size, hidden_size, num_layers, bidirectional = bidirectional)\n",
    "\n",
    "            self.fc = torch.nn.Linear(hidden_size * self.num_directions, output_size)\n",
    "\n",
    "        def initHidden(self, batch_size):\n",
    "            hidden = torch.zeros(self.num_layers * self.num_directions, batch_size, self.hidden_size)\n",
    "            return createTensor(hidden)\n",
    "\n",
    "        def forward(self, input, seq_lengths):\n",
    "            input = input.t()\n",
    "            batch_size = input.size(1)\n",
    "            hidden = self.initHidden(batch_size)\n",
    "\n",
    "            embedding = self.embedding(input)\n",
    "            gru_input = pack_padded_sequence(embedding, seq_lengths)\n",
    "            output, hidden = self.gru(gru_input, hidden)\n",
    "            if self.num_directions == 2:\n",
    "                hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim = 1)\n",
    "            else:\n",
    "                hidden_cat = hidden[-1]\n",
    "\n",
    "            fc_output = self.fc(hidden_cat)\n",
    "            return fc_output\n",
    "\n",
    "    # smiles to ASCIIlist\n",
    "    def smiles_to_ASCIIlist(smiles_list):\n",
    "        ASCIIlist = [ord(smiles) for smiles in smiles_list]\n",
    "        return ASCIIlist\n",
    "\n",
    "    def makeTensors(smiles_list, tox_list):\n",
    "        smiles_sequences = [smiles_to_ASCIIlist(smiles) for smiles in smiles_list]\n",
    "        smiles_seq_lens = torch.LongTensor([len(name_ASCII) for name_ASCII in smiles_sequences])\n",
    "\n",
    "        smiles_tensor = torch.zeros(len(smiles_sequences), smiles_seq_lens.max()).long()\n",
    "        for index, (smiles_sequence, smiles_seq_len) in enumerate(zip(smiles_sequences, smiles_seq_lens), 0):\n",
    "            smiles_tensor[index, 0:smiles_seq_len] = torch.LongTensor(smiles_sequence)\n",
    "\n",
    "        ordered_smiles_seq_lens, len_indexes = smiles_seq_lens.sort(dim = 0, descending = True)\n",
    "        ordered_smiles_tensor = smiles_tensor[len_indexes]\n",
    "        ordered_tox_list = tox_list[len_indexes]\n",
    "\n",
    "        return createTensor(ordered_smiles_tensor), createTensor(ordered_smiles_seq_lens), createTensor(ordered_tox_list) \n",
    "\n",
    "    def train():\n",
    "        loss = 0.0\n",
    "        for batch_index, (smiles, tox) in enumerate(train_loader):\n",
    "\n",
    "            inputs, seq_lens, targets = makeTensors(smiles, tox) \n",
    "            outputs = classifier_model(inputs, seq_lens)\n",
    "            targets = targets.to(torch.float32).reshape(-1,1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss += loss.item()\n",
    "\n",
    "            if batch_index % 10 == 9:\n",
    "                print('time_elapsed: {:.1f}m {:.1f}s, Epoch {}, '.format(timePassed(start_time)[0], timePassed(start_time)[1], epoch), end = '')\n",
    "                print(f'[{(batch_index+1) * len(inputs)} / {len(training_set)}] ', end = '')\n",
    "                print(f'loss = {loss / ((batch_index+1) * len(inputs))}')\n",
    "\n",
    "        return loss/len(train_loader)\n",
    "\n",
    "    def test():\n",
    "        correct = 0\n",
    "        total_samples = len(test_set)\n",
    "        with torch.no_grad():\n",
    "            pred = []\n",
    "            obs = []\n",
    "            for i, (smiles, tox) in enumerate(test_loader):\n",
    "                inputs, seq_lens, targets = makeTensors(smiles, tox)\n",
    "                outputs = classifier_model(inputs, seq_lens)\n",
    "                pred.append(outputs.data)\n",
    "                obs.append(targets.data.reshape(-1,1))\n",
    "            pred = np.vstack(pred).ravel()\n",
    "            obs = np.vstack(obs).ravel()\n",
    "            r2 = r2_score(obs, pred)\n",
    "            Mse = mse(obs, pred)\n",
    "            print('r2 on test: %.3f %%' % (100 * r2), 'mse on test: %.5f \\n' % (Mse))\n",
    "        return r2, Mse, pred, obs\n",
    "\n",
    "    def timePassed(start_time):\n",
    "        time_passed = time.time() - start_time\n",
    "        minute = math.floor(time_passed / 60)\n",
    "        second = time_passed - minute * 60\n",
    "        return [minute, second]\n",
    "\n",
    "    seed = 1\n",
    "    os.makedirs(\"./results/{}/DL/{}/RNN/test/\".format(data, seed), exist_ok=True)\n",
    "    os.makedirs(\"./results/{}/DL/{}/RNN/train/\".format(data, seed), exist_ok=True)\n",
    "    \n",
    "    # data load\n",
    "    train_mols = Chem.SDMolSupplier(\"./data/{}/{}_training.sdf\".format(data, data))\n",
    "    train_smiles = [Chem.MolToSmiles(mol) for mol in train_mols]\n",
    "    train_smiles_len = [len(smiles) for smiles in train_smiles]\n",
    "    train_tox = [float(mol.GetProp(\"Tox\")) for mol in train_mols]\n",
    "    training_set = [(train_smiles[i], train_tox[i]) for i in range(len(train_smiles))]\n",
    "\n",
    "    test_mols = Chem.SDMolSupplier(\"./data/{}/{}_prediction.sdf\".format(data, data))\n",
    "    test_smiles = [Chem.MolToSmiles(mol) for mol in test_mols]\n",
    "    test_smiles_len = [len(smiles) for smiles in test_smiles]\n",
    "    test_tox = [float(mol.GetProp(\"Tox\")) for mol in test_mols]\n",
    "    test_set = [(test_smiles[i], test_tox[i]) for i in range(len(test_smiles))]\n",
    "\n",
    "    n_chars = 0\n",
    "    for smiles in train_smiles:\n",
    "        for char in smiles:\n",
    "            if n_chars < ord(char):\n",
    "                n_chars = ord(char)\n",
    "    for smiles in test_smiles:\n",
    "        for char in smiles:\n",
    "            if n_chars < ord(char):\n",
    "                n_chars = ord(char)\n",
    "    n_chars = n_chars+1\n",
    "    output_size = 1\n",
    "    \n",
    "    train_loader = DataLoader(dataset = training_set, batch_size = batch_size, shuffle = True)\n",
    "    test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    classifier_model = RNNRegress(n_chars, hidden_size, output_size, n_layers) # input_size, hidden_size, output_size, num_layers\n",
    "    if USE_GPU:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        classifier_model.to(device)\n",
    "    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(classifier_model.parameters(), lr = 0.001, weight_decay=10 ** (-5.0))\n",
    "    \n",
    "    # training and test\n",
    "    start_time = time.time()\n",
    "    print(\"The num of total training epochs is %d. \" % n_epoch)\n",
    "    r2_list = []\n",
    "    Mse_list = []\n",
    "    best_r2 = 0\n",
    "    train_loss = []\n",
    "    for epoch in range(n_epoch):\n",
    "        train_loss.append(train())\n",
    "        r2, Mse, pred, obs = test()\n",
    "        r2_list.append(r2)\n",
    "        Mse_list.append(Mse)\n",
    "        if best_r2 < r2:\n",
    "            best_r2 = r2\n",
    "            pd.DataFrame([pred, obs], index=[\"pred\", \"true\"]).T.to_csv('./results/{}/DL/{}/RNN/test/test_pred_all.csv'.format(data, seed), index=0)\n",
    "    plt.plot(np.arange(1, n_epoch+1), r2_list)\n",
    "    plt.plot(np.arange(1, n_epoch+1), Mse_list)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"r2 & MSE\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    pd.DataFrame(r2_list).to_csv(\"./results/{}/DL/{}/RNN/test/scores_r2.csv\".format(data, seed), index=0)\n",
    "    pd.DataFrame(Mse_list).to_csv(\"./results/{}/DL/{}/RNN/test/scores_mse.csv\".format(data, seed), index=0)\n",
    "    pd.DataFrame(train_loss).to_csv(\"./results/{}/DL/{}/RNN/test/train_loss.csv\".format(data, seed), index=0)\n",
    "    \n",
    "    print(r2_list.index(max(r2_list)))\n",
    "    print(max(r2_list))\n",
    "    \n",
    "data_train_test(\"IGC50\", hidden_size=200, n_layers=2, n_epoch=100, batch_size=16, USE_GPU = False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "325.85px",
    "left": "713.833px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "77b022008d7e49a7577e3989aa2de88606942ee75ef8e6a397bf4b790024deae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
